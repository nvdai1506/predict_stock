{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  python 3.7\r\n",
    "#  tensorflow 1.14\r\n",
    "#  pip install tensorflow==1.14"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import utils as u\r\n",
    "\r\n",
    "import math\r\n",
    "import tensorflow as tf\r\n",
    "print(tf.version.VERSION)\r\n",
    "# import tensorflow.compat.v1 as tf\r\n",
    "# tf.disable_v2_behavior() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"NSE-TATA.csv\")\r\n",
    "df.head()\r\n",
    "\r\n",
    "#Analyze the closing prices from dataframe:+\r\n",
    "df[\"Date\"] = pd.to_datetime(df.Date,format=\"%Y-%m-%d\")\r\n",
    "df.index = df['Date']\r\n",
    "\r\n",
    "#Sort the dataset on date time and # filter “Date” and “Close” columns:\r\n",
    "data = df.sort_index(ascending=True,axis=0)\r\n",
    "new_dataset = pd.DataFrame(index=range(0,len(df)),columns=['Date','Close'])\r\n",
    "for i in range(0,len(data)):\r\n",
    "    new_dataset[\"Date\"][i] = data['Date'][i]\r\n",
    "    new_dataset[\"Close\"][i] = data[\"Close\"][i]\r\n",
    "# Normalize the new filtered dataset:\r\n",
    "new_dataset.index = new_dataset.Date\r\n",
    "new_dataset.drop(\"Date\",axis=1,inplace=True)\r\n",
    "dataset = new_dataset.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = dataset.flatten()\r\n",
    "series = np.array(dataset)\r\n",
    "n_windows = 10  \r\n",
    "n_input =  1\r\n",
    "n_output = 1\r\n",
    "size_train = 1001\r\n",
    "## Split data\r\n",
    "train = series[:size_train]\r\n",
    "test = series[size_train:1232]\r\n",
    "print(train.shape, test.shape)\r\n",
    "def create_batches(windows, input, output):\r\n",
    "    ## Create X         \r\n",
    "        x_data = train[:size_train-1] # Select the data\r\n",
    "        x_batches = x_data.reshape(-1, windows, input)  # Reshape the data \r\n",
    "        x_test_data = test[:len(test)-1]\r\n",
    "        x_test = x_test_data.reshape(-1, windows, input)  # Reshape the data\r\n",
    "    ## Create y\r\n",
    "        y_data = train[n_output:size_train]\r\n",
    "        y_batches = y_data.reshape(-1, windows, output)\r\n",
    "        y_test_data = test[n_output:]\r\n",
    "        y_test = y_test_data.reshape(-1, windows, output)\r\n",
    "        return x_batches, y_batches, x_test, y_test\r\n",
    "        \r\n",
    "x_batches, y_batches, x_test, y_test = create_batches(  windows = n_windows,\r\n",
    "                                                        input = n_input,\r\n",
    "                                                        output = n_output)\r\n",
    "print(test.shape)\r\n",
    "\r\n",
    "print(x_batches.shape, y_batches.shape)\r\n",
    "print(x_test.shape, y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.compat.v1.disable_eager_execution()\r\n",
    "tf.compat.v1.placeholder(tf.float32, [None, n_windows, n_input]) \t"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.reset_default_graph()\r\n",
    "r_neuron = 120    \r\n",
    "\r\n",
    "## 1. Construct the tensors\r\n",
    "X = tf.placeholder(tf.float32, [None, n_windows, n_input])   \r\n",
    "y = tf.placeholder(tf.float32, [None, n_windows, n_output])\r\n",
    "\r\n",
    "## 2. create the model\r\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=r_neuron, activation=tf.nn.relu)   \r\n",
    "rnn_output, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)              \r\n",
    "\r\n",
    "stacked_rnn_output = tf.reshape(rnn_output, [-1, r_neuron])          \r\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_output, n_output)       \r\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_windows, n_output])   \r\n",
    "\r\n",
    "## 3. Loss + optimization\r\n",
    "learning_rate = 0.001  \r\n",
    " \r\n",
    "loss = tf.reduce_sum(tf.square(outputs - y))    \r\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)         \r\n",
    "training_op = optimizer.minimize(loss)                                          \r\n",
    "\r\n",
    "init = tf.global_variables_initializer() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "saver = tf.train.Saver()\r\n",
    "tf.add_to_collection('outputs', outputs)\r\n",
    "iteration = 1500 \r\n",
    "\r\n",
    "with tf.Session() as sess:\r\n",
    "    init.run()\r\n",
    "    for iters in range(iteration):\r\n",
    "        sess.run(training_op, feed_dict={X: x_batches, y: y_batches})\r\n",
    "        if iters % 150 == 0:\r\n",
    "            mse = loss.eval(feed_dict={X: x_batches, y: y_batches})\r\n",
    "            print(iters, \"\\tMSE:\", mse)\r\n",
    "    print('outputs: ', outputs)\r\n",
    "    y_pred = sess.run(outputs, feed_dict={X: x_test})\r\n",
    "    save_path = saver.save(sess, \"RNN.ckpt\")\r\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_test = y_test.flatten()\r\n",
    "y_pred = y_pred.flatten()\r\n",
    "#get the root mean squared error(RMSE)\r\n",
    "rmse = np.sqrt(np.mean(y_pred - y_test)**2)\r\n",
    "print('rmse: ', rmse)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_RNN(meta_file,x_test,y_test):\r\n",
    "    sess = tf.Session()\r\n",
    "    new_saver = tf.train.import_meta_graph(meta_file)\r\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./'))\r\n",
    "    outputs2 = tf.get_collection('outputs')\r\n",
    "    y_pred = sess.run(outputs2[0],feed_dict={X: x_test})\r\n",
    "    rmse = np.sqrt(np.mean(y_pred - y_test)**2)\r\n",
    "    print('rmse: ', rmse)\r\n",
    "load_RNN(\"RNN.ckpt.meta\",x_test,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "plt.title(\"Forecast vs Actual\", fontsize=14)\r\n",
    "plt.plot(pd.Series(np.ravel(y_test)), \"bo\", markersize=8, label=\"Actual\", color='green')\r\n",
    "plt.plot(pd.Series(np.ravel(y_pred)), \"r.\", markersize=8, label=\"Forecast\", color='red')\r\n",
    "plt.legend(loc=\"lower left\")\r\n",
    "plt.xlabel(\"Time\")\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}